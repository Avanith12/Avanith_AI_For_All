{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdfeaff",
   "metadata": {},
   "source": [
    "## 1: Google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4437ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 20:04:39.120397: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 20:04:39.158188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746144279.203874 3737146 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746144279.210571 3737146 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-01 20:04:39.233494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 20:04:43.520369: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/sbatch2/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training student model from scratch...\n",
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.1179 - loss: 3.3744 - val_accuracy: 0.1050 - val_loss: 2.3292\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 5s/step - accuracy: 0.1961 - loss: 2.7531 - val_accuracy: 0.0950 - val_loss: 2.4420\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 5s/step - accuracy: 0.2451 - loss: 2.4690 - val_accuracy: 0.1200 - val_loss: 2.5226\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - accuracy: 0.2882 - loss: 2.2754 - val_accuracy: 0.1400 - val_loss: 2.5242\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - accuracy: 0.2943 - loss: 2.2161 - val_accuracy: 0.1450 - val_loss: 2.5284\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 5s/step - accuracy: 0.3248 - loss: 2.0089 - val_accuracy: 0.2000 - val_loss: 2.5036\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - accuracy: 0.3492 - loss: 1.9492 - val_accuracy: 0.1500 - val_loss: 2.5788\n",
      "\n",
      "📊 Evaluating on test data...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.1561 - loss: 2.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Loss: 2.5788 | Test Accuracy: 15.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 5s/step - categorical_accuracy: 0.1145 - loss: 2.2971 - val_categorical_accuracy: 0.2100 - val_loss: 2.2366\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 5s/step - categorical_accuracy: 0.2321 - loss: 2.2510 - val_categorical_accuracy: 0.2800 - val_loss: 2.2190\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - categorical_accuracy: 0.2909 - loss: 2.2305 - val_categorical_accuracy: 0.3050 - val_loss: 2.2002\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - categorical_accuracy: 0.3208 - loss: 2.2019 - val_categorical_accuracy: 0.3350 - val_loss: 2.1771\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - categorical_accuracy: 0.4097 - loss: 2.1690 - val_categorical_accuracy: 0.4250 - val_loss: 2.1622\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - categorical_accuracy: 0.4188 - loss: 2.1581 - val_categorical_accuracy: 0.4250 - val_loss: 2.1526\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - categorical_accuracy: 0.4519 - loss: 2.1484 - val_categorical_accuracy: 0.3900 - val_loss: 2.1803\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - categorical_accuracy: 0.4002 - loss: 2.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Variables\n",
    "train_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/google_dataset_800'\n",
    "test_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/google_dataset_200'\n",
    "model_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/student_model.h5'\n",
    "scratch_model_name = '5x_dataset_google'\n",
    "distill_model_name = '5x_dataset_google'\n",
    "custom_module_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final'\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Path setup for imports\n",
    "sys.path.append(custom_module_path)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Image preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Training from scratch\n",
    "from scratch import train_student_from_scratch\n",
    "\n",
    "history, eval_results = train_student_from_scratch(\n",
    "    model_path=model_path,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=scratch_model_name\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Knowledge Distillation\n",
    "from kd import kd\n",
    "\n",
    "distiller, history, evaluation = kd(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=distill_model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4012db",
   "metadata": {},
   "source": [
    "## 2. Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf79748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 20:44:45.102880: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 20:44:45.124152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746146685.147037 3750949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746146685.153979 3750949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-01 20:44:45.177320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 20:44:48.962078: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/sbatch2/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training student model from scratch...\n",
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 637ms/step - accuracy: 0.1226 - loss: 3.4374 - val_accuracy: 0.1300 - val_loss: 2.3112\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 584ms/step - accuracy: 0.1888 - loss: 2.8070 - val_accuracy: 0.1400 - val_loss: 2.3447\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 585ms/step - accuracy: 0.1953 - loss: 2.6804 - val_accuracy: 0.1150 - val_loss: 2.3816\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 574ms/step - accuracy: 0.2057 - loss: 2.4781 - val_accuracy: 0.1200 - val_loss: 2.4077\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 567ms/step - accuracy: 0.2548 - loss: 2.3629 - val_accuracy: 0.1550 - val_loss: 2.4089\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 564ms/step - accuracy: 0.2905 - loss: 2.1810 - val_accuracy: 0.1250 - val_loss: 2.4504\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 570ms/step - accuracy: 0.2890 - loss: 2.2416 - val_accuracy: 0.1700 - val_loss: 2.4311\n",
      "\n",
      "📊 Evaluating on test data...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 344ms/step - accuracy: 0.1816 - loss: 2.3449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Loss: 2.4311 | Test Accuracy: 17.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 630ms/step - categorical_accuracy: 0.1202 - loss: 2.3024 - val_categorical_accuracy: 0.1000 - val_loss: 2.2958\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 574ms/step - categorical_accuracy: 0.0952 - loss: 2.2947 - val_categorical_accuracy: 0.1050 - val_loss: 2.2867\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 564ms/step - categorical_accuracy: 0.1239 - loss: 2.2809 - val_categorical_accuracy: 0.1900 - val_loss: 2.2899\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 573ms/step - categorical_accuracy: 0.1647 - loss: 2.2747 - val_categorical_accuracy: 0.2500 - val_loss: 2.2574\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 567ms/step - categorical_accuracy: 0.2664 - loss: 2.2400 - val_categorical_accuracy: 0.2000 - val_loss: 2.2692\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 575ms/step - categorical_accuracy: 0.2785 - loss: 2.2251 - val_categorical_accuracy: 0.2800 - val_loss: 2.2422\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 586ms/step - categorical_accuracy: 0.3598 - loss: 2.2127 - val_categorical_accuracy: 0.2650 - val_loss: 2.2334\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 327ms/step - categorical_accuracy: 0.2606 - loss: 2.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Variables\n",
    "\n",
    "train_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/bing_dataset_800'\n",
    "test_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/bing_dataset_200'\n",
    "model_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/student_model.h5'\n",
    "scratch_model_name = '5x_dataset_bing'\n",
    "distill_model_name = '5x_dataset_bing'\n",
    "\n",
    "custom_module_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final'\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Path setup for imports\n",
    "sys.path.append(custom_module_path)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Image preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Training from scratch\n",
    "from scratch import train_student_from_scratch\n",
    "\n",
    "history, eval_results = train_student_from_scratch(\n",
    "    model_path=model_path,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=scratch_model_name\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Knowledge Distillation\n",
    "from kd import kd\n",
    "\n",
    "distiller, history, evaluation = kd(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=distill_model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc9ad1",
   "metadata": {},
   "source": [
    "## 3. Google + Bing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66666e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 21:08:25.802933: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 21:08:25.823044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746148105.845127 3762791 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746148105.851754 3762791 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-01 21:08:25.873846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 21:08:30.419283: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training student model from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huuthanhvy.nguyen001/anaconda3/envs/sbatch2/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 0.1190 - loss: 3.3403 - val_accuracy: 0.1300 - val_loss: 2.2866\n",
      "Epoch 2/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6s/step - accuracy: 0.1646 - loss: 2.9567 - val_accuracy: 0.1650 - val_loss: 2.3084\n",
      "Epoch 3/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6s/step - accuracy: 0.2348 - loss: 2.5453 - val_accuracy: 0.1800 - val_loss: 2.3156\n",
      "Epoch 4/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5s/step - accuracy: 0.3099 - loss: 2.2803 - val_accuracy: 0.2250 - val_loss: 2.4024\n",
      "Epoch 5/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step - accuracy: 0.2689 - loss: 2.2826 - val_accuracy: 0.1600 - val_loss: 2.4483\n",
      "Epoch 6/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5s/step - accuracy: 0.2938 - loss: 2.1055 - val_accuracy: 0.2000 - val_loss: 2.4628\n",
      "Epoch 7/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6s/step - accuracy: 0.3182 - loss: 2.0189 - val_accuracy: 0.1650 - val_loss: 2.5491\n",
      "\n",
      "📊 Evaluating on test data...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.1682 - loss: 2.5779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Loss: 2.5491 | Test Accuracy: 16.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - categorical_accuracy: 0.1033 - loss: 2.3055 - val_categorical_accuracy: 0.1500 - val_loss: 2.2978\n",
      "Epoch 2/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step - categorical_accuracy: 0.1610 - loss: 2.2948 - val_categorical_accuracy: 0.1300 - val_loss: 2.2650\n",
      "Epoch 3/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5s/step - categorical_accuracy: 0.1136 - loss: 2.2675 - val_categorical_accuracy: 0.2900 - val_loss: 2.2456\n",
      "Epoch 4/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step - categorical_accuracy: 0.1970 - loss: 2.2447 - val_categorical_accuracy: 0.2800 - val_loss: 2.2284\n",
      "Epoch 5/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5s/step - categorical_accuracy: 0.2959 - loss: 2.2305 - val_categorical_accuracy: 0.2350 - val_loss: 2.2064\n",
      "Epoch 6/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6s/step - categorical_accuracy: 0.3418 - loss: 2.1997 - val_categorical_accuracy: 0.3550 - val_loss: 2.1897\n",
      "Epoch 7/7\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6s/step - categorical_accuracy: 0.4397 - loss: 2.1645 - val_categorical_accuracy: 0.3800 - val_loss: 2.1733\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - categorical_accuracy: 0.3919 - loss: 2.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Variables\n",
    "\n",
    "train_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/combined_google_bing_dataset_800'\n",
    "test_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/google_dataset_200'\n",
    "model_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/student_model.h5'\n",
    "scratch_model_name = '5x_dataset_combined_google_bing'\n",
    "distill_model_name = '5x_dataset_combined_google_bing'\n",
    "\n",
    "custom_module_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final'\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Path setup for imports\n",
    "sys.path.append(custom_module_path)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Image preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Training from scratch\n",
    "from scratch import train_student_from_scratch\n",
    "\n",
    "history, eval_results = train_student_from_scratch(\n",
    "    model_path=model_path,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=scratch_model_name\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Knowledge Distillation\n",
    "from kd import kd\n",
    "\n",
    "distiller, history, evaluation = kd(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=distill_model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1f6ba",
   "metadata": {},
   "source": [
    "## 4. Google + Bing Data + Augmented Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22cea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training student model from scratch...\n",
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.1454 - loss: 3.2794 - val_accuracy: 0.1850 - val_loss: 2.2858\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.1530 - loss: 3.0033 - val_accuracy: 0.2200 - val_loss: 2.3147\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.2115 - loss: 2.5388 - val_accuracy: 0.2200 - val_loss: 2.3618\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.2747 - loss: 2.3413 - val_accuracy: 0.2600 - val_loss: 2.2797\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.2549 - loss: 2.3633 - val_accuracy: 0.2550 - val_loss: 2.2594\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.3145 - loss: 2.0876 - val_accuracy: 0.2700 - val_loss: 2.2226\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.3104 - loss: 2.0768 - val_accuracy: 0.1650 - val_loss: 2.2424\n",
      "\n",
      "📊 Evaluating on test data...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.1407 - loss: 2.3685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Loss: 2.2424 | Test Accuracy: 16.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - categorical_accuracy: 0.0829 - loss: 2.3026 - val_categorical_accuracy: 0.1200 - val_loss: 2.2607\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - categorical_accuracy: 0.1566 - loss: 2.2705 - val_categorical_accuracy: 0.2800 - val_loss: 2.2207\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - categorical_accuracy: 0.2904 - loss: 2.2412 - val_categorical_accuracy: 0.2850 - val_loss: 2.2162\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - categorical_accuracy: 0.2484 - loss: 2.2402 - val_categorical_accuracy: 0.4150 - val_loss: 2.1514\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - categorical_accuracy: 0.3487 - loss: 2.2074 - val_categorical_accuracy: 0.4750 - val_loss: 2.1474\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - categorical_accuracy: 0.4719 - loss: 2.1724 - val_categorical_accuracy: 0.5400 - val_loss: 2.1282\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - categorical_accuracy: 0.4829 - loss: 2.1505 - val_categorical_accuracy: 0.6150 - val_loss: 2.0752\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - categorical_accuracy: 0.6140 - loss: 2.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Variables\n",
    "\n",
    "train_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/combined_google_bing_augmented_800'\n",
    "\n",
    "test_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/google_dataset_200'\n",
    "\n",
    "model_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/student_model.h5'\n",
    "\n",
    "scratch_model_name = '5x_dataset_combined_google_bing_augmented'\n",
    "\n",
    "distill_model_name = '5x_dataset_combined_google_bing_augmented'\n",
    "\n",
    "custom_module_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final'\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Path setup for imports\n",
    "sys.path.append(custom_module_path)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Image preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Training from scratch\n",
    "from scratch import train_student_from_scratch\n",
    "\n",
    "history, eval_results = train_student_from_scratch(\n",
    "    model_path=model_path,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=scratch_model_name\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Knowledge Distillation\n",
    "from kd import kd\n",
    "\n",
    "distiller, history, evaluation = kd(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=distill_model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134eb2f",
   "metadata": {},
   "source": [
    "# 5: Diffuser (AI Generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d812872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 14:29:38.748532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-02 14:29:38.772143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746210578.793519 3900518 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746210578.800044 3900518 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-02 14:29:38.825794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Variables\n",
    "\n",
    "train_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/ai_generated_images_800_diffusers'\n",
    "\n",
    "test_dir = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/smalldataset/google_dataset_200'\n",
    "\n",
    "model_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final/student_model.h5'\n",
    "\n",
    "scratch_model_name = '5x_dataset_combined_google_bing_augmented'\n",
    "\n",
    "distill_model_name = '5x_dataset_combined_google_bing_augmented'\n",
    "\n",
    "custom_module_path = '/hpcstor6/scratch01/h/huuthanhvy.nguyen001/diffusion/Final'\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Path setup for imports\n",
    "sys.path.append(custom_module_path)\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Image preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c021b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 14:29:45.875531: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "/home/huuthanhvy.nguyen001/anaconda3/envs/sbatch2/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training student model from scratch...\n",
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.1456 - loss: 3.3074 - val_accuracy: 0.1000 - val_loss: 2.2902\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.2402 - loss: 2.5828 - val_accuracy: 0.1000 - val_loss: 2.4133\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.3074 - loss: 2.2423 - val_accuracy: 0.1850 - val_loss: 2.5295\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.3794 - loss: 1.9491 - val_accuracy: 0.1850 - val_loss: 2.6252\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.4292 - loss: 1.7802 - val_accuracy: 0.1600 - val_loss: 2.7746\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.4113 - loss: 1.7148 - val_accuracy: 0.1900 - val_loss: 2.8167\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.4729 - loss: 1.5184 - val_accuracy: 0.1250 - val_loss: 2.8689\n",
      "\n",
      "📊 Evaluating on test data...\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.1085 - loss: 2.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Loss: 2.8689 | Test Accuracy: 12.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - categorical_accuracy: 0.0916 - loss: 2.2990 - val_categorical_accuracy: 0.2000 - val_loss: 2.2491\n",
      "Epoch 2/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - categorical_accuracy: 0.2703 - loss: 2.2311 - val_categorical_accuracy: 0.2300 - val_loss: 2.2523\n",
      "Epoch 3/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - categorical_accuracy: 0.4006 - loss: 2.1883 - val_categorical_accuracy: 0.3200 - val_loss: 2.2144\n",
      "Epoch 4/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - categorical_accuracy: 0.4405 - loss: 2.1475 - val_categorical_accuracy: 0.3300 - val_loss: 2.2131\n",
      "Epoch 5/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - categorical_accuracy: 0.5576 - loss: 2.0992 - val_categorical_accuracy: 0.3150 - val_loss: 2.2346\n",
      "Epoch 6/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - categorical_accuracy: 0.6863 - loss: 2.0347 - val_categorical_accuracy: 0.2850 - val_loss: 2.2742\n",
      "Epoch 7/7\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - categorical_accuracy: 0.6720 - loss: 2.0357 - val_categorical_accuracy: 0.3100 - val_loss: 2.2784\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - categorical_accuracy: 0.3153 - loss: 2.2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────\n",
    "# Training from scratch\n",
    "from scratch import train_student_from_scratch\n",
    "\n",
    "history, eval_results = train_student_from_scratch(\n",
    "    model_path=model_path,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=scratch_model_name\n",
    ")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# Knowledge Distillation\n",
    "from kd import kd\n",
    "\n",
    "distiller, history, evaluation = kd(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    model_save_name=distill_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6973f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbatch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
